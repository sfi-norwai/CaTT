















 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 15/16 [01:55<00:07,  7.70s/it]
  0%|                                                                                                                                   | 0/4 [00:00<?, ?it/s]



 75%|████████████████████████████████████████████████████████████████████████████████████████████▎                              | 3/4 [00:14<00:04,  4.71s/it]
  0%|                                                                                                                                  | 0/16 [00:00<?, ?it/s]













 81%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 13/16 [01:41<00:22,  7.39s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14d1efe20>
Traceback (most recent call last):
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1479, in __del__
    self._shutdown_workers()
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1443, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/Users/shamba/anaconda3/lib/python3.11/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 13/16 [01:42<00:23,  7.92s/it]
Traceback (most recent call last):
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/MarginMultistepCL/single_fulloss.py", line 265, in <module>
    main(train_loader, valid_loader)
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/MarginMultistepCL/single_fulloss.py", line 125, in main
    features = attn_model(time_series)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/MarginMultistepCL/src/models/attention_model.py", line 70, in forward
    x = self.transformer_encoder(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/MarginMultistepCL/src/models/attention_model.py", line 59, in forward
    x = layer(x)
        ^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/MarginMultistepCL/src/models/attention_model.py", line 40, in forward
    x, _ = self.self_attn(x, x, x)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py", line 5442, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py", line 1858, in softmax
    ret = input.softmax(dim)
          ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt