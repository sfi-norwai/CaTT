[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|                                                                                                                                        | 0/500 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/NODATA_MarginMultistepCL/baselines/cost.py", line 397, in <module>
    main(train_loader, valid_loader, valid_balanced_dataloader, seed)
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/NODATA_MarginMultistepCL/baselines/cost.py", line 210, in main
    cost_model, train_loss = attn_model(x_q, x_k)
                             ^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1561, in _call_impl
    result = forward_call(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/NODATA_MarginMultistepCL/baselines/src/models/costmodel.py", line 136, in forward
    q_t = F.normalize(self.head_q(q_t[:, rand_idx]), dim=-1)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: mat1 and mat2 shapes cannot be multiplied (8x16 and 32x32)
torch.Size([8, 300, 32])
ModuleList(
  (0): BandedFourierLayer()
)
tensor([[[ 6.0093e-03,  1.3273e-01,  3.4311e-02,  ..., -4.6696e-02,
           2.4003e-03,  1.0801e-01],
         [-3.2196e-02,  1.0722e-01,  7.6088e-02,  ..., -8.0056e-02,
          -3.3093e-02,  9.7772e-02],
         [ 1.0153e-01,  1.4227e-01,  1.1181e-01,  ..., -1.1788e-01,
          -6.6064e-02, -2.0512e-02],
         ...,
         [ 4.9127e-02, -4.9829e-02,  4.6367e-02,  ..., -2.6051e-02,
          -6.1555e-02,  1.9234e-03],
         [-7.9931e-03, -1.2613e-01,  6.1980e-02,  ...,  1.2041e-02,
           6.3675e-03,  7.0671e-02],
         [ 1.2890e-01, -2.8988e-02,  1.8080e-01,  ..., -2.7057e-01,
          -3.9241e-02,  1.2897e-01]],
        [[ 5.8156e-02,  3.1088e-02,  6.4080e-02,  ...,  4.4248e-04,
           4.1087e-02,  5.5662e-02],
         [-8.4984e-03,  1.0943e-01,  1.5959e-01,  ..., -1.4160e-01,
          -1.3894e-01,  1.5649e-01],
         [ 8.1012e-02,  5.5069e-02,  4.3693e-02,  ..., -1.4157e-01,
          -7.4753e-02,  1.6554e-01],
         ...,
         [-8.8459e-02,  5.1975e-02,  1.5515e-01,  ..., -1.1591e-01,
          -3.0147e-02,  5.1174e-02],
         [ 3.1705e-02, -2.9884e-02,  8.1761e-02,  ..., -7.0828e-02,
          -4.0705e-02,  7.1967e-02],
         [-4.8749e-03,  6.6071e-02,  5.7652e-02,  ..., -6.4944e-02,
          -4.9181e-02,  8.9683e-02]],
        [[ 4.6749e-02,  7.2353e-03,  5.1307e-02,  ...,  5.4960e-02,
           5.3114e-02,  7.1631e-02],
         [ 3.3228e-02,  1.1068e-01,  1.6216e-02,  ..., -1.5706e-01,
          -2.2561e-01,  1.5077e-01],
         [ 3.3233e-03,  1.2428e-01,  7.1032e-02,  ..., -1.4847e-01,
          -1.2104e-01, -1.6249e-02],
         ...,
         [-1.8476e-02, -1.5128e-01,  2.2078e-01,  ..., -1.7344e-01,
           1.0641e-01,  1.5870e-02],
         [-6.8400e-02, -1.8371e-01,  4.9485e-02,  ...,  2.2228e-02,
           2.6732e-02,  2.2213e-01],
         [ 2.3264e-01, -6.3164e-02,  1.7361e-01,  ..., -5.2477e-02,
          -1.0605e-01,  6.6971e-02]],
        ...,
        [[ 2.5213e-02,  6.1439e-02,  9.5257e-02,  ..., -3.0736e-02,
          -2.0103e-02,  7.4645e-02],
         [ 3.3877e-02,  5.1674e-02,  4.2784e-02,  ..., -9.0799e-02,
          -2.2722e-02,  1.3955e-01],
         [ 4.0843e-02,  7.2794e-02,  1.0219e-01,  ..., -8.8088e-02,
          -8.3085e-02,  1.4174e-01],
         ...,
         [ 5.0685e-02, -1.6599e-01,  3.8992e-02,  ..., -1.2827e-01,
          -5.6961e-02,  3.0776e-02],
         [ 1.1177e-02,  6.8641e-02,  1.3320e-01,  ..., -1.0177e-01,
           8.8344e-02,  1.8710e-01],
         [ 2.1112e-03,  2.2819e-02,  9.5365e-02,  ..., -7.9797e-02,
           1.0847e-02,  1.0562e-01]],
        [[ 3.4000e-02, -8.0081e-02,  6.9633e-02,  ...,  1.4179e-01,
           2.1115e-02,  4.1078e-02],
         [-2.5022e-02, -4.4453e-02,  8.4597e-02,  ..., -1.2440e-01,
          -7.9666e-02,  6.4187e-02],
         [ 1.1530e-02,  6.2168e-02,  1.0962e-01,  ..., -8.4636e-02,
          -6.5007e-02,  5.6327e-02],
         ...,
         [ 3.7239e-02,  1.9835e-01, -1.0489e-02,  ..., -2.2864e-01,
           9.2344e-02,  1.7498e-01],
         [ 9.4033e-02, -5.2583e-02,  1.6997e-01,  ..., -2.7975e-01,
           7.5409e-02,  1.8780e-02],
         [ 2.1870e-04,  6.3501e-02,  2.2985e-01,  ..., -1.1410e-01,
          -8.0206e-02, -2.3649e-02]],
        [[ 7.9715e-02,  8.4345e-02,  3.2313e-02,  ..., -2.6878e-02,
          -2.3434e-02,  5.5059e-02],
         [ 2.9421e-02,  1.2976e-01,  1.0030e-01,  ..., -1.6723e-01,
          -1.1872e-01,  5.5824e-02],
         [ 8.1549e-03,  4.8116e-02,  3.1740e-02,  ..., -8.2665e-02,
          -8.3160e-02,  1.5353e-01],
         ...,
         [ 3.6663e-03, -3.7836e-02,  2.5613e-01,  ..., -1.5699e-01,
           2.0331e-01, -7.2713e-02],
         [-6.9448e-02,  2.3564e-02,  2.0646e-01,  ..., -9.7895e-02,
           2.5043e-02, -4.5290e-02],
         [ 9.5331e-02,  6.7681e-02, -3.9002e-03,  ...,  1.7153e-01,
           6.1054e-02, -1.3456e-03]]], grad_fn=<MeanBackward1>)
tensor([[[ 0.1294, -0.1477,  0.0209,  ...,  0.0000,  0.0000, -0.2906],
         [-0.0069, -0.0937,  0.2961,  ..., -0.0042, -0.0518, -0.0596],
         [-0.1871,  0.2654, -0.1797,  ...,  0.3172,  0.5418,  0.0049],
         ...,
         [ 0.2212, -0.1413,  0.0501,  ...,  0.0580,  0.0711,  0.0606],
         [ 0.2124,  0.2370, -0.0035,  ..., -0.0231, -0.1180, -0.1517],
         [-0.2270,  0.0570,  0.4400,  ...,  0.1921,  0.0333, -0.1092]],
        [[ 0.1305,  0.0504,  0.1808,  ...,  0.0143, -0.0412, -0.0101],
         [-0.0000, -0.2811, -0.0584,  ...,  0.0651,  0.0468, -0.0185],
         [-0.0431,  0.1513,  0.0797,  ...,  0.0269,  0.0979,  0.0059],
         ...,
         [-0.0241,  0.3039, -0.1827,  ...,  0.0046, -0.0611,  0.0655],
         [-0.0348, -0.0065,  0.0000,  ...,  0.0218,  0.0589, -0.1666],
         [-0.0967,  0.0377,  0.0928,  ...,  0.0818,  0.0149,  0.1410]],
        [[ 0.0542,  0.0000, -0.0133,  ...,  0.0000,  0.0636, -0.0332],
         [ 0.1254, -0.0456, -0.1072,  ...,  0.3110,  0.0866,  0.1979],
         [ 0.1007,  0.1049,  0.0670,  ...,  0.0181, -0.1583, -0.0771],
         ...,
         [ 0.0818,  0.0552,  0.0940,  ..., -0.0000, -0.0222,  0.0064],
         [ 0.0902,  0.1078,  0.0101,  ..., -0.0342, -0.0378,  0.0000],
         [ 0.0000,  0.1152, -0.0007,  ..., -0.1263, -0.0195,  0.0346]],
        ...,
        [[-0.0668,  0.1177,  0.0426,  ...,  0.0446, -0.0000,  0.0777],
         [ 0.0177,  0.0335, -0.0041,  ...,  0.0576,  0.0989,  0.0373],
         [-0.0474, -0.1117, -0.2770,  ...,  0.0231, -0.0121,  0.1097],
         ...,
         [-0.0720, -0.1898, -0.1343,  ...,  0.0570,  0.0000,  0.0000],
         [-0.1256,  0.0133, -0.0677,  ..., -0.0608,  0.0039, -0.0832],
         [ 0.0964,  0.0209,  0.0234,  ...,  0.0074,  0.1159,  0.0276]],
        [[-0.0218, -0.2077,  0.0000,  ..., -0.1770, -0.3397,  0.2122],
         [ 0.0752, -0.1321,  0.0254,  ...,  0.0000, -0.1025, -0.0301],
         [-0.1853,  0.1979, -0.2262,  ..., -0.0791, -0.1966, -0.2891],
         ...,
         [-0.1537,  0.2500,  0.0659,  ..., -0.0299, -0.0177,  0.0895],
         [-0.1186,  0.1283, -0.1418,  ..., -0.0262, -0.0631, -0.0974],
         [ 0.0000,  0.0678,  0.1326,  ..., -0.4251, -0.1747, -0.0931]],
        [[-0.0661,  0.1511,  0.0324,  ...,  0.0861, -0.1027, -0.0679],
         [-0.0357, -0.0385,  0.2202,  ..., -0.0040, -0.1629,  0.0773],
         [ 0.0000,  0.0480,  0.1341,  ..., -0.0000,  0.0989, -0.0194],
         ...,
         [ 0.0675,  0.0000, -0.0018,  ...,  0.2520,  0.0966,  0.1056],
         [-0.0056,  0.1937, -0.0229,  ..., -0.1726,  0.0425, -0.1521],
         [-0.2827, -0.0163,  0.2114,  ..., -0.1921,  0.0063,  0.0844]]],
       grad_fn=<MulBackward0>)