[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.




  1%|â–‹                                                                                           | 4/499 [02:10<4:29:56, 32.72s/it]
Traceback (most recent call last):
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/NODATA_MarginMultistepCL/baselines/cpc.py", line 419, in <module>
    main(train_loader, valid_loader, valid_balanced_dataloader, seed)
  File "/Users/shamba/Desktop/Paper 1 - HAR RL/NODATA_MarginMultistepCL/baselines/cpc.py", line 217, in main
    train_loss.backward()
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/Users/shamba/anaconda3/lib/python3.11/site-packages/wandb/wandb_torch.py", line 271, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt