{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89280962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision version: 0.17.0\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import pickle\n",
    "from scipy import interpolate\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from info_nce import InfoNCE\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import einops\n",
    "from scipy.stats import mode\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import src.config, src.utils, src.models, src.data\n",
    "import torchvision\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from torch.nn import GRU, Linear, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9b25bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae4b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "# from deepecg.config.config import DATA_DIR\n",
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8830949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "afib_dict = {\"AFIB\":0, \"AFL\":1, \"J\":2, \"N\":3}\n",
    "flipped_afib_dict = {0: \"AFIB\", 1: \"AFL\", 2: \"J\", 3: \"N\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811db2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFDB(object):\n",
    "    \"\"\"\n",
    "        The MIT-BIH Atrial Fibrillation Database\n",
    "        https://physionet.org/physiobank/database/afdb/\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Set attributes\n",
    "        self.db_name = 'afdb'\n",
    "        self.raw_path = os.path.join(DATA_DIR, 'mittecg')\n",
    "        self.processed_path = os.path.join(DATA_DIR, 'processed')\n",
    "        self.label_dict = {\n",
    "                'AFIB': 'atrial fibrillation',\n",
    "                'ASYS': 'asystole',\n",
    "                'B': 'ventricular bigeminy',\n",
    "                'BI': 'first degree heart block',\n",
    "                'HGEA': 'high grade ventricular ectopic activity',\n",
    "                'N': 'normal sinus rhythm',\n",
    "                'NSR': 'normal sinus rhythm',\n",
    "                'NOD': 'nodal (\"AV junctional\") rhythm',\n",
    "                'NOISE': 'noise',\n",
    "                'PM': 'pacemaker (paced rhythm)',\n",
    "                'SBR': 'sinus bradycardia',\n",
    "                'SVTA': 'supraventricular tachyarrhythmia',\n",
    "                'VER': 'ventricular escape rhythm',\n",
    "                'VF': 'ventricular fibrillation',\n",
    "                'VFIB': 'ventricular fibrillation',\n",
    "                'VFL': 'ventricular flutter',\n",
    "                'VT': 'ventricular tachycardia'\n",
    "            }\n",
    "\n",
    "        self.fs = 300\n",
    "        self.length = 60\n",
    "        self.length_sp = self.length * self.fs\n",
    "        self.record_ids = None\n",
    "        self.sections = None\n",
    "        self.samples = None\n",
    "        self.labels = None\n",
    "\n",
    "    def generate_db(self):\n",
    "        \"\"\"Generate raw and processed databases.\"\"\"\n",
    "        # Generate raw database\n",
    "        self.generate_raw_db()\n",
    "\n",
    "        # Generate processed database\n",
    "        self.generate_processed_db()\n",
    "\n",
    "    def generate_raw_db(self):\n",
    "        \"\"\"Generate the raw version of the MIT-BIH Atrial Fibrillation database in the 'raw' folder.\"\"\"\n",
    "        # Download database\n",
    "        if len(os.listdir(self.raw_path))==0:\n",
    "            print('Generating Raw MIT-BIH Atrial Fibrillation Database ...')\n",
    "            wfdb.dl_database(self.db_name, self.raw_path)\n",
    "            print('Complete!\\n')\n",
    "\n",
    "        # Get list of recordings\n",
    "        self.record_ids = [file.split('.')[0] for file in os.listdir(self.raw_path) if '.dat' in file]\n",
    "\n",
    "    def generate_processed_db(self):\n",
    "        \"\"\"Generate the processed version of the MIT-BIH Atrial Fibrillation database in the 'processed' folder.\"\"\"\n",
    "        print('Generating Processed MIT-BIH Atrial Fibrillation Database ...')\n",
    "        all_signals, all_labels = self._get_sections()\n",
    "\n",
    "        signal_lens = [len(sig) for sig in all_labels]\n",
    "        all_signals = np.array([sig[:,:min(signal_lens)] for sig in all_signals])\n",
    "        all_labels = np.array([sig[:min(signal_lens)] for sig in all_labels])\n",
    "\n",
    "        \n",
    "\n",
    "        # Normalize signals\n",
    "        data_n, data_n = self._normalize(all_signals, all_signals)\n",
    "\n",
    "\n",
    "        # Save signals to file\n",
    "        if not os.path.exists(self.processed_path):\n",
    "            os.mkdir(self.processed_path)\n",
    "        \n",
    "        with open(os.path.join(self.processed_path, 'tensor_data.pkl'), 'wb') as f:\n",
    "            pickle.dump(data_n, f)\n",
    "        with open(os.path.join(self.processed_path, 'tensor_label.pkl'), 'wb') as f:\n",
    "            pickle.dump(all_labels, f)\n",
    "        \n",
    "\n",
    "    def _normalize(self, train_data, test_data):\n",
    "        \"\"\" Calculate the mean and std of each feature from the training set\n",
    "        \"\"\"\n",
    "        feature_means = np.mean(train_data, axis=(0, 2))\n",
    "        feature_std = np.std(train_data, axis=(0, 2))\n",
    "        train_data_n = (train_data - feature_means[np.newaxis, :, np.newaxis]) / \\\n",
    "                       np.where(feature_std == 0, 1, feature_std)[np.newaxis, :, np.newaxis]\n",
    "        test_data_n = (test_data - feature_means[np.newaxis, :, np.newaxis]) /\\\n",
    "                      np.where(feature_std == 0, 1, feature_std)[np.newaxis, :, np.newaxis]\n",
    "        return train_data_n, test_data_n\n",
    "\n",
    "    def _get_sections(self):\n",
    "        \"\"\"Collect continuous arrhythmia sections.\"\"\"\n",
    "        # Empty dictionary for arrhythmia sections\n",
    "        all_signals = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Loop through records\n",
    "        for record_id in self.record_ids:\n",
    "            # Import recording\n",
    "            record = wfdb.rdrecord(os.path.join(self.raw_path, record_id))\n",
    "\n",
    "            # Import annotations\n",
    "            annotation = wfdb.rdann(os.path.join(self.raw_path, record_id), 'atr')\n",
    "\n",
    "            # Get sample frequency\n",
    "            fs = record.__dict__['fs']\n",
    "\n",
    "            # Get waveform\n",
    "            waveform = record.__dict__['p_signal']  #shape: (length, n_channels=2)\n",
    "\n",
    "            # labels\n",
    "            labels = [label[1:] for label in annotation.__dict__['aux_note']]\n",
    "\n",
    "            # Samples\n",
    "            sample = annotation.__dict__['sample']\n",
    "\n",
    "            padded_labels = np.zeros(len(waveform))\n",
    "            labels = [label.strip('\\x00') for label in labels]\n",
    "            for i,l in enumerate(labels):\n",
    "\n",
    "                if i==len(labels)-1:\n",
    "                    padded_labels[sample[i]:] = afib_dict[l]\n",
    "                else:\n",
    "                    padded_labels[sample[i]:sample[i+1]] = afib_dict[l]\n",
    "            padded_labels = padded_labels[sample[0]:]\n",
    "            all_labels.append(padded_labels)\n",
    "            all_signals.append(waveform[sample[0]:,:].T)\n",
    "\n",
    "        return all_signals, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d391f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_stft(x_train, n_fft = 100, hop_length=50, win_length=100, phase = False, stack_axes = True):\n",
    "    train_tensor = torch.tensor(x_train).transpose(1,2).reshape(-1, 2).transpose(0,1)\n",
    "    \n",
    "    x = torch.stft(\n",
    "        input=train_tensor,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window=torch.hann_window(win_length),\n",
    "        center=False,\n",
    "        return_complex=True)  # [num_channels, num_bins, num_frames]\n",
    "\n",
    "    x_cartesian = src.utils.complex_to_cartesian(x)\n",
    "    x_magnitude = src.utils.complex_to_magnitude(x, expand=True)\n",
    "\n",
    "    x = x_cartesian if phase else x_magnitude\n",
    "    if stack_axes:\n",
    "        # Stack all spectrograms and put time dim first:\n",
    "        # [num_channels, num_bins, num_frames, stft_parts] ->\n",
    "        # [num_frames, num_channels x num_bins x stft_parts]\n",
    "        x = einops.rearrange(x, 'C F T P -> T (C F P)')  # P=2\n",
    "    else:\n",
    "        x = einops.rearrange(x, 'C F T P -> T C F P')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9718a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a pickle file\n",
    "def load_pickle_file(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def feature_stft(x_train, n_fft = 100, hop_length=50, win_length=100, phase = False, stack_axes = True):\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    train_tensor = torch.tensor(x_train).transpose(1,2).reshape(-1, 2).transpose(0,1)\n",
    "    \n",
    "    x = torch.stft(\n",
    "        input=train_tensor,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window=torch.hann_window(win_length),\n",
    "        center=False,\n",
    "        return_complex=True)  # [num_channels, num_bins, num_frames]\n",
    "\n",
    "    x_cartesian = src.utils.complex_to_cartesian(x)\n",
    "    x_magnitude = src.utils.complex_to_magnitude(x, expand=True)\n",
    "\n",
    "    x = x_cartesian if phase else x_magnitude\n",
    "    if stack_axes:\n",
    "        # Stack all spectrograms and put time dim first:\n",
    "        # [num_channels, num_bins, num_frames, stft_parts] ->\n",
    "        # [num_frames, num_channels x num_bins x stft_parts]\n",
    "        x = einops.rearrange(x, 'C F T P -> T (C F P)')  # P=2\n",
    "    else:\n",
    "        x = einops.rearrange(x, 'C F T P -> T C F P')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def windowed_labels(\n",
    "    labels,\n",
    "    num_labels,\n",
    "    frame_length,\n",
    "    frame_step=None,\n",
    "    pad_end=False,\n",
    "    kind='density',\n",
    "):\n",
    "    \"\"\"Generates labels that correspond to STFTs\n",
    "\n",
    "    With kind=None we are able to split the given labels\n",
    "    array into batches. (T, C) -> (B, T', C)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : np.array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "    \"\"\"\n",
    "    labels = torch.tensor(labels).view(-1)\n",
    "    \n",
    "    # Labels should be a single vector (int-likes) or kind has to be None\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    if kind is not None and not labels.ndim == 1:\n",
    "        raise ValueError('Labels must be a vector')\n",
    "    if not (labels >= 0).all():\n",
    "        raise ValueError('All labels must be >= 0')\n",
    "    if not (labels < num_labels).all():\n",
    "        raise ValueError(f'All labels must be < {num_labels} (num_labels)')\n",
    "    # Kind determines how labels in each window should be processed\n",
    "    if not kind in {'counts', 'density', 'onehot', 'argmax', None}:\n",
    "        raise ValueError('`kind` must be in {counts, density, onehot, argmax, None}')\n",
    "    # Let frame_step default to one full frame_length\n",
    "    frame_step = frame_length if frame_step is None else frame_step\n",
    "    # Process labels with a sliding window. TODO: vectorize?\n",
    "    output = []\n",
    "    for i in range(0, len(labels), frame_step):\n",
    "        chunk = labels[i:i+frame_length]\n",
    "        chunk = chunk.astype(int)\n",
    "        # Ignore incomplete end chunk unless padding is enabled\n",
    "        if len(chunk) < frame_length and not pad_end:\n",
    "            continue\n",
    "        # Just append the chunk if kind is None\n",
    "        if kind == None:\n",
    "            output.append(chunk)\n",
    "            continue\n",
    "        # Count the occurences of each label\n",
    "        counts = np.bincount(chunk, minlength=num_labels)\n",
    "        # Then process based on kind\n",
    "        if kind == 'counts':\n",
    "            output.append(counts)\n",
    "        elif kind == 'density':\n",
    "            output.append(counts / len(chunk))\n",
    "        elif kind == 'onehot':\n",
    "            one_hot = np.zeros(num_labels)\n",
    "            one_hot[np.argmax(counts)] = 1\n",
    "            output.append(one_hot)\n",
    "        elif kind == 'argmax':\n",
    "            output.append(np.argmax(counts))\n",
    "    if pad_end:\n",
    "        return output\n",
    "    else:\n",
    "        return torch.tensor(output)\n",
    "    \n",
    "class STFTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, class_to_exclude=3, n_fft = 250, hop_length=125, win_length=250, seq_length=500, num_labels=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_data (Tensor): The input features, e.g., from STFT.\n",
    "            y_data (Tensor): The corresponding labels, windowed and processed.\n",
    "            seq_length (int): The length of each sequence.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load each of the pickle files\n",
    "        tensor_data = load_pickle_file(f'{data_path}/tensor_data.pkl')\n",
    "        tensor_label = load_pickle_file(f'{data_path}/tensor_label.pkl')\n",
    "        \n",
    "        \n",
    "        x_data = feature_stft(tensor_data, n_fft = n_fft, hop_length=hop_length, win_length=win_length)\n",
    "        y_data = windowed_labels(labels=tensor_label, num_labels=num_labels, frame_length=n_fft, frame_step=hop_length, kind='argmax')\n",
    "\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.seq_length = seq_length\n",
    "        self.class_to_exclude = class_to_exclude\n",
    "        \n",
    "        # Create a mask that filters out the class_to_exclude\n",
    "        mask = self.y_data != self.class_to_exclude\n",
    "\n",
    "        # Apply the mask to filter the data\n",
    "        self.x_data = self.x_data[mask]\n",
    "        self.y_data = self.y_data[mask]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of full sequences in the dataset\n",
    "        return len(self.x_data) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input, label) for the given index.\n",
    "        The input is reshaped to (seq_length, features).\n",
    "        \"\"\"\n",
    "        start_idx = idx * self.seq_length\n",
    "        end_idx = start_idx + self.seq_length\n",
    "\n",
    "        # Extract the sequence of data and corresponding labels\n",
    "        x_seq = self.x_data[start_idx:end_idx]\n",
    "        y_seq = self.y_data[start_idx:end_idx]\n",
    "\n",
    "        return x_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9581cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 2, 8324850)\n"
     ]
    }
   ],
   "source": [
    "dataset = STFTDataset(\"data/processed\", n_fft = 250, seq_length=119, class_to_exclude=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4392ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Processed MIT-BIH Atrial Fibrillation Database ...\n"
     ]
    }
   ],
   "source": [
    "a = AFDB()\n",
    "a.generate_raw_db()\n",
    "a.generate_processed_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7359aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a pickle file\n",
    "def load_pickle_file(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Load each of the pickle files\n",
    "tensor_data = load_pickle_file('./data/processed/tensor_data.pkl')\n",
    "tensor_label = load_pickle_file('./data/processed/tensor_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f1533b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 2, 8324850)\n"
     ]
    }
   ],
   "source": [
    "x_data = feature_stft(tensor_data, n_fft = 250, hop_length=125, win_length=250)\n",
    "y_data = windowed_labels(labels=tensor_label, num_labels=4, frame_length=250, frame_step=125, kind='argmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "187427dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1531771, 252])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7613851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1531771])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a097981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 612853 occurrences\n",
      "Label 1: 4974 occurrences\n",
      "Label 2: 661 occurrences\n",
      "Label 3: 913283 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Get unique labels and their counts\n",
    "unique_labels, counts = np.unique(y_data, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94890952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 625 times\n",
      "Label 0: 1341 times\n",
      "Label 0: 881 times\n",
      "Label 1: 955 times\n",
      "Label 0: 12314 times\n",
      "Label 1: 2139 times\n",
      "Label 0: 2133 times\n",
      "Label 0: 689 times\n",
      "Label 0: 91 times\n",
      "Label 0: 168 times\n",
      "Label 1: 12 times\n",
      "Label 0: 391 times\n",
      "Label 0: 732 times\n",
      "Label 0: 805 times\n",
      "Label 0: 846 times\n",
      "Label 0: 471 times\n",
      "Label 0: 487 times\n",
      "Label 0: 1073 times\n",
      "Label 0: 140 times\n",
      "Label 0: 155 times\n",
      "Label 0: 829 times\n",
      "Label 0: 202 times\n",
      "Label 0: 697 times\n",
      "Label 0: 262 times\n",
      "Label 0: 152 times\n",
      "Label 0: 288 times\n",
      "Label 0: 149 times\n",
      "Label 0: 358 times\n",
      "Label 0: 214 times\n",
      "Label 0: 140 times\n",
      "Label 0: 198 times\n",
      "Label 0: 253 times\n",
      "Label 0: 376 times\n",
      "Label 0: 73 times\n",
      "Label 0: 114 times\n",
      "Label 0: 330 times\n",
      "Label 0: 151 times\n",
      "Label 0: 844 times\n",
      "Label 0: 408 times\n",
      "Label 0: 522 times\n",
      "Label 0: 213 times\n",
      "Label 0: 524 times\n",
      "Label 0: 528 times\n",
      "Label 0: 154 times\n",
      "Label 0: 460 times\n",
      "Label 0: 47 times\n",
      "Label 0: 474 times\n",
      "Label 0: 1545 times\n",
      "Label 0: 206 times\n",
      "Label 0: 87 times\n",
      "Label 0: 4212 times\n",
      "Label 0: 177 times\n",
      "Label 0: 4495 times\n",
      "Label 1: 236 times\n",
      "Label 0: 530 times\n",
      "Label 2: 4 times\n",
      "Label 0: 70 times\n",
      "Label 0: 214 times\n",
      "Label 0: 4325 times\n",
      "Label 2: 172 times\n",
      "Label 0: 9 times\n",
      "Label 0: 86 times\n",
      "Label 0: 78 times\n",
      "Label 0: 282 times\n",
      "Label 0: 2187 times\n",
      "Label 0: 109 times\n",
      "Label 0: 39 times\n",
      "Label 0: 148 times\n",
      "Label 0: 150 times\n",
      "Label 0: 1272 times\n",
      "Label 0: 1564 times\n",
      "Label 0: 1681 times\n",
      "Label 0: 1234 times\n",
      "Label 0: 6790 times\n",
      "Label 2: 4 times\n",
      "Label 0: 201 times\n",
      "Label 2: 3 times\n",
      "Label 0: 1593 times\n",
      "Label 0: 14610 times\n",
      "Label 2: 5 times\n",
      "Label 0: 38 times\n",
      "Label 0: 17089 times\n",
      "Label 0: 6 times\n",
      "Label 0: 33 times\n",
      "Label 0: 104 times\n",
      "Label 0: 31 times\n",
      "Label 0: 8 times\n",
      "Label 0: 24 times\n",
      "Label 0: 36 times\n",
      "Label 0: 13 times\n",
      "Label 0: 659 times\n",
      "Label 0: 34 times\n",
      "Label 0: 10 times\n",
      "Label 0: 9 times\n",
      "Label 0: 11 times\n",
      "Label 0: 52 times\n",
      "Label 0: 24702 times\n",
      "Label 0: 14331 times\n",
      "Label 0: 44399 times\n",
      "Label 2: 14 times\n",
      "Label 0: 6 times\n",
      "Label 0: 31 times\n",
      "Label 0: 57 times\n",
      "Label 0: 134 times\n",
      "Label 0: 16 times\n",
      "Label 0: 302 times\n",
      "Label 0: 201 times\n",
      "Label 0: 1014 times\n",
      "Label 0: 158 times\n",
      "Label 0: 561 times\n",
      "Label 0: 793 times\n",
      "Label 0: 34 times\n",
      "Label 0: 151 times\n",
      "Label 0: 45 times\n",
      "Label 0: 66599 times\n",
      "Label 0: 99 times\n",
      "Label 0: 43796 times\n",
      "Label 0: 878 times\n",
      "Label 0: 138 times\n",
      "Label 0: 839 times\n",
      "Label 0: 275 times\n",
      "Label 0: 56 times\n",
      "Label 0: 19 times\n",
      "Label 0: 221 times\n",
      "Label 0: 243 times\n",
      "Label 0: 120 times\n",
      "Label 0: 133 times\n",
      "Label 0: 120 times\n",
      "Label 0: 738 times\n",
      "Label 0: 142 times\n",
      "Label 0: 223 times\n",
      "Label 0: 363 times\n",
      "Label 0: 512 times\n",
      "Label 0: 278 times\n",
      "Label 0: 285 times\n",
      "Label 0: 185 times\n",
      "Label 0: 125 times\n",
      "Label 0: 260 times\n",
      "Label 0: 50 times\n",
      "Label 0: 189 times\n",
      "Label 0: 197 times\n",
      "Label 0: 241 times\n",
      "Label 0: 80 times\n",
      "Label 0: 398 times\n",
      "Label 0: 101 times\n",
      "Label 0: 195 times\n",
      "Label 0: 176 times\n",
      "Label 0: 95 times\n",
      "Label 0: 97 times\n",
      "Label 0: 109 times\n",
      "Label 0: 71 times\n",
      "Label 0: 116 times\n",
      "Label 0: 101 times\n",
      "Label 0: 330 times\n",
      "Label 0: 436 times\n",
      "Label 0: 275 times\n",
      "Label 0: 181 times\n",
      "Label 0: 140 times\n",
      "Label 0: 129 times\n",
      "Label 0: 326 times\n",
      "Label 0: 137 times\n",
      "Label 0: 54 times\n",
      "Label 0: 222 times\n",
      "Label 0: 206 times\n",
      "Label 0: 55 times\n",
      "Label 0: 321 times\n",
      "Label 0: 101 times\n",
      "Label 0: 260 times\n",
      "Label 0: 152 times\n",
      "Label 0: 207 times\n",
      "Label 0: 61 times\n",
      "Label 0: 100 times\n",
      "Label 0: 163 times\n",
      "Label 0: 107 times\n",
      "Label 0: 25 times\n",
      "Label 0: 133 times\n",
      "Label 0: 415 times\n",
      "Label 0: 202 times\n",
      "Label 0: 107 times\n",
      "Label 0: 48 times\n",
      "Label 0: 21 times\n",
      "Label 0: 141 times\n",
      "Label 0: 135 times\n",
      "Label 0: 78 times\n",
      "Label 1: 26 times\n",
      "Label 0: 261 times\n",
      "Label 0: 122 times\n",
      "Label 0: 123 times\n",
      "Label 0: 12 times\n",
      "Label 0: 163 times\n",
      "Label 0: 162 times\n",
      "Label 0: 46 times\n",
      "Label 0: 816 times\n",
      "Label 0: 1603 times\n",
      "Label 0: 1305 times\n",
      "Label 1: 20 times\n",
      "Label 0: 111 times\n",
      "Label 1: 36 times\n",
      "Label 0: 286 times\n",
      "Label 1: 444 times\n",
      "Label 0: 357 times\n",
      "Label 1: 7 times\n",
      "Label 0: 36 times\n",
      "Label 0: 194 times\n",
      "Label 0: 64 times\n",
      "Label 0: 44 times\n",
      "Label 0: 35 times\n",
      "Label 0: 308 times\n",
      "Label 0: 40 times\n",
      "Label 0: 36 times\n",
      "Label 0: 272 times\n",
      "Label 0: 35 times\n",
      "Label 0: 113 times\n",
      "Label 0: 290 times\n",
      "Label 0: 122 times\n",
      "Label 0: 5 times\n",
      "Label 0: 887 times\n",
      "Label 0: 154 times\n",
      "Label 0: 145 times\n",
      "Label 0: 105 times\n",
      "Label 0: 1905 times\n",
      "Label 0: 1575 times\n",
      "Label 0: 9 times\n",
      "Label 0: 882 times\n",
      "Label 0: 274 times\n",
      "Label 0: 155 times\n",
      "Label 0: 1063 times\n",
      "Label 0: 1281 times\n",
      "Label 0: 28 times\n",
      "Label 0: 4994 times\n",
      "Label 0: 12700 times\n",
      "Label 0: 86 times\n",
      "Label 0: 777 times\n",
      "Label 0: 1303 times\n",
      "Label 0: 79 times\n",
      "Label 0: 3237 times\n",
      "Label 0: 1114 times\n",
      "Label 0: 1830 times\n",
      "Label 0: 21 times\n",
      "Label 0: 17 times\n",
      "Label 0: 10643 times\n",
      "Label 0: 693 times\n",
      "Label 0: 734 times\n",
      "Label 0: 18 times\n",
      "Label 0: 5198 times\n",
      "Label 0: 111 times\n",
      "Label 0: 8 times\n",
      "Label 0: 11 times\n",
      "Label 0: 4 times\n",
      "Label 0: 8 times\n",
      "Label 0: 21 times\n",
      "Label 0: 9 times\n",
      "Label 0: 27 times\n",
      "Label 0: 85 times\n",
      "Label 0: 11053 times\n",
      "Label 1: 16 times\n",
      "Label 0: 35 times\n",
      "Label 1: 10 times\n",
      "Label 0: 80 times\n",
      "Label 0: 64 times\n",
      "Label 0: 31 times\n",
      "Label 0: 16404 times\n",
      "Label 0: 11438 times\n",
      "Label 1: 101 times\n",
      "Label 0: 40864 times\n",
      "Label 0: 35 times\n",
      "Label 0: 46097 times\n",
      "Label 0: 5 times\n",
      "Label 0: 3648 times\n",
      "Label 0: 804 times\n",
      "Label 0: 8088 times\n",
      "Label 0: 1830 times\n",
      "Label 0: 368 times\n",
      "Label 0: 356 times\n",
      "Label 0: 8012 times\n",
      "Label 0: 16070 times\n",
      "Label 0: 1404 times\n",
      "Label 0: 92 times\n",
      "Label 0: 1572 times\n",
      "Label 0: 973 times\n",
      "Label 0: 527 times\n",
      "Label 0: 2142 times\n",
      "Label 2: 48 times\n",
      "Label 0: 135 times\n",
      "Label 2: 55 times\n",
      "Label 0: 51 times\n",
      "Label 2: 31 times\n",
      "Label 0: 47 times\n",
      "Label 2: 28 times\n",
      "Label 0: 87 times\n",
      "Label 2: 157 times\n",
      "Label 0: 206 times\n",
      "Label 2: 140 times\n",
      "Label 0: 136 times\n",
      "Label 0: 4 times\n",
      "Label 0: 268 times\n",
      "Label 0: 15 times\n",
      "Label 0: 34 times\n",
      "Label 0: 9 times\n",
      "Label 0: 10 times\n",
      "Label 0: 66599 times\n",
      "Label 0: 468 times\n",
      "Label 0: 13 times\n",
      "Label 1: 972 times\n",
      "Label 0: 3522 times\n",
      "Label 0: 17 times\n",
      "Label 0: 669 times\n"
     ]
    }
   ],
   "source": [
    "def count_consecutive_labels(labels):\n",
    "    if len(labels) == 0:\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    current_label = labels[0]\n",
    "    count = 1\n",
    "\n",
    "    for i in range(1, len(labels)):\n",
    "        if labels[i] == current_label:\n",
    "            count += 1\n",
    "        else:\n",
    "            result.append((current_label, count))\n",
    "            current_label = labels[i]\n",
    "            count = 1\n",
    "\n",
    "    # Append the last label count\n",
    "    result.append((current_label, count))\n",
    "    return result\n",
    "\n",
    "labels = y_data\n",
    "consecutive_counts = count_consecutive_labels(labels)\n",
    "\n",
    "for label, count in consecutive_counts:\n",
    "    if label != 3:\n",
    "        print(f\"Label {label}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17afd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, seq_length, class_to_exclude):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_data (Tensor): The input features, e.g., from STFT.\n",
    "            y_data (Tensor): The corresponding labels, windowed and processed.\n",
    "            seq_length (int): The length of each sequence.\n",
    "        \"\"\"\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.seq_length = seq_length\n",
    "        self.class_to_exclude = class_to_exclude\n",
    "        \n",
    "        # Create a mask that filters out the class_to_exclude\n",
    "        mask = self.y_data != self.class_to_exclude\n",
    "\n",
    "        # Apply the mask to filter the data\n",
    "        self.x_data = self.x_data[mask]\n",
    "        self.y_data = self.y_data[mask]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of full sequences in the dataset\n",
    "        return len(self.x_data) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple (input, label) for the given index.\n",
    "        The input is reshaped to (seq_length, features).\n",
    "        \"\"\"\n",
    "        start_idx = idx * self.seq_length\n",
    "        end_idx = start_idx + self.seq_length\n",
    "\n",
    "        # Extract the sequence of data and corresponding labels\n",
    "        x_seq = self.x_data[start_idx:end_idx]\n",
    "        y_seq = self.y_data[start_idx:end_idx]\n",
    "\n",
    "        return x_seq, y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9325d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRandomSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "\n",
    "        indices = list(range(len(self.data_source)))\n",
    "        \n",
    "        remaining = len(indices) % self.batch_size\n",
    "        if remaining > 0:\n",
    "            indices = indices[:-remaining]\n",
    "        final_indices = np.reshape(indices, (-1, self.batch_size))\n",
    "\n",
    "        # Shuffle the batches\n",
    "        np.random.shuffle(final_indices)\n",
    "\n",
    "        # Flatten the list of batches to get the final order of indices\n",
    "        final_indices = [idx for batch in final_indices for idx in batch]\n",
    "        \n",
    "        return iter(final_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f738fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(x_data, y_data, seq_length=500, class_to_exclude=3)\n",
    "valid_split = 0.2\n",
    "            \n",
    "valid_amount = int(np.floor(len(dataset)*valid_split))\n",
    "train_amount = len(dataset) - valid_amount\n",
    "\n",
    "\n",
    "train_indices = list(range(train_amount))\n",
    "valid_indices = list(range(train_amount, train_amount + valid_amount))\n",
    "\n",
    "# Create subsets\n",
    "train_ds = Subset(dataset, train_indices)\n",
    "valid_ds = Subset(dataset, valid_indices)\n",
    "\n",
    "# train_ds, valid_ds = random_split(dataset, [train_amount, valid_amount])\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "batch_size= 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=batch_size,\n",
    "#     sampler=SequentialRandomSampler(train_ds, batch_size),\n",
    "    shuffle = True,\n",
    "    num_workers=0,\n",
    "    drop_last = True,\n",
    "    worker_init_fn=seed_worker\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_ds,\n",
    "    batch_size=batch_size,\n",
    "#             sampler=SequentialRandomSampler(valid_ds, args['batch_size']),\n",
    "    shuffle = False,\n",
    "    num_workers=0,\n",
    "    drop_last = True,\n",
    "    worker_init_fn=seed_worker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adae35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10298"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f393153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2574"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7d92196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10298"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "549ec4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2574"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70e3b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 454757 occurrences\n",
      "Label 1: 4002 occurrences\n",
      "Label 2: 202 occurrences\n",
      "Label 3: 766501 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader to iterate over the dataset\n",
    "data_loader = DataLoader(train_ds, batch_size=512, shuffle=False)\n",
    "\n",
    "# Initialize a list to store all labels\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the DataLoader to collect all labels\n",
    "for _, labels in data_loader:\n",
    "    all_labels.extend(labels.numpy())  # Convert the labels to numpy and extend the list\n",
    "\n",
    "# Convert the list of labels to a numpy array\n",
    "tall_labels = np.array(all_labels)\n",
    "\n",
    "# Get unique labels and their counts\n",
    "unique_labels, counts = np.unique(tall_labels, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4947811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 158093 occurrences\n",
      "Label 1: 972 occurrences\n",
      "Label 2: 459 occurrences\n",
      "Label 3: 146782 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader to iterate over the dataset\n",
    "data_loader = DataLoader(valid_ds, batch_size=512, shuffle=False)\n",
    "\n",
    "# Initialize a list to store all labels\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the DataLoader to collect all labels\n",
    "for _, labels in data_loader:\n",
    "    all_labels.extend(labels.numpy())  # Convert the labels to numpy and extend the list\n",
    "\n",
    "# Convert the list of labels to a numpy array\n",
    "vall_labels = np.array(all_labels)\n",
    "\n",
    "# Get unique labels and their counts\n",
    "unique_labels, counts = np.unique(vall_labels, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7957c6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 3: 17897 times\n",
      "Label 0: 625 times\n",
      "Label 3: 49 times\n",
      "Label 0: 1341 times\n",
      "Label 3: 61 times\n",
      "Label 0: 881 times\n",
      "Label 3: 50583 times\n",
      "Label 1: 955 times\n",
      "Label 3: 142 times\n",
      "Label 0: 12314 times\n",
      "Label 3: 16270 times\n",
      "Label 1: 2139 times\n",
      "Label 3: 159 times\n",
      "Label 0: 2133 times\n",
      "Label 3: 66 times\n",
      "Label 0: 689 times\n",
      "Label 3: 112 times\n",
      "Label 0: 91 times\n",
      "Label 3: 52 times\n",
      "Label 0: 168 times\n",
      "Label 3: 7470 times\n",
      "Label 1: 12 times\n",
      "Label 3: 43610 times\n",
      "Label 0: 391 times\n",
      "Label 3: 145 times\n",
      "Label 0: 732 times\n",
      "Label 3: 288 times\n",
      "Label 0: 805 times\n",
      "Label 3: 101 times\n",
      "Label 0: 846 times\n",
      "Label 3: 342 times\n",
      "Label 0: 471 times\n",
      "Label 3: 86 times\n",
      "Label 0: 487 times\n",
      "Label 3: 121 times\n",
      "Label 0: 1073 times\n",
      "Label 3: 82 times\n",
      "Label 0: 140 times\n",
      "Label 3: 103 times\n",
      "Label 0: 155 times\n",
      "Label 3: 4477 times\n",
      "Label 0: 829 times\n",
      "Label 3: 59 times\n",
      "Label 0: 202 times\n",
      "Label 3: 94 times\n",
      "Label 0: 697 times\n",
      "Label 3: 61 times\n",
      "Label 0: 262 times\n",
      "Label 3: 71 times\n",
      "Label 0: 152 times\n",
      "Label 3: 43 times\n",
      "Label 0: 288 times\n",
      "Label 3: 78 times\n",
      "Label 0: 149 times\n",
      "Label 3: 99 times\n",
      "Label 0: 358 times\n",
      "Label 3: 78 times\n",
      "Label 0: 214 times\n",
      "Label 3: 88 times\n",
      "Label 0: 140 times\n",
      "Label 3: 106 times\n",
      "Label 0: 198 times\n",
      "Label 3: 111 times\n",
      "Label 0: 253 times\n",
      "Label 3: 65 times\n",
      "Label 0: 376 times\n",
      "Label 3: 55 times\n",
      "Label 0: 73 times\n",
      "Label 3: 61 times\n",
      "Label 0: 114 times\n",
      "Label 3: 92 times\n",
      "Label 0: 330 times\n",
      "Label 3: 103 times\n",
      "Label 0: 151 times\n",
      "Label 3: 106 times\n",
      "Label 0: 844 times\n",
      "Label 3: 87 times\n",
      "Label 0: 408 times\n",
      "Label 3: 271 times\n",
      "Label 0: 522 times\n",
      "Label 3: 69 times\n",
      "Label 0: 213 times\n",
      "Label 3: 70 times\n",
      "Label 0: 524 times\n",
      "Label 3: 39 times\n",
      "Label 0: 528 times\n",
      "Label 3: 60 times\n",
      "Label 0: 154 times\n",
      "Label 3: 69 times\n",
      "Label 0: 460 times\n",
      "Label 3: 69 times\n",
      "Label 0: 47 times\n",
      "Label 3: 17 times\n",
      "Label 0: 474 times\n",
      "Label 3: 109 times\n",
      "Label 0: 1545 times\n",
      "Label 3: 119 times\n",
      "Label 0: 206 times\n",
      "Label 3: 79 times\n",
      "Label 0: 87 times\n",
      "Label 3: 17906 times\n",
      "Label 0: 4212 times\n",
      "Label 3: 61 times\n",
      "Label 0: 177 times\n",
      "Label 3: 190 times\n",
      "Label 0: 4495 times\n",
      "Label 1: 236 times\n",
      "Label 0: 530 times\n",
      "Label 2: 4 times\n",
      "Label 3: 182 times\n",
      "Label 0: 70 times\n",
      "Label 3: 77 times\n",
      "Label 0: 214 times\n",
      "Label 3: 120 times\n",
      "Label 0: 4325 times\n",
      "Label 2: 172 times\n",
      "Label 0: 9 times\n",
      "Label 3: 592 times\n",
      "Label 0: 86 times\n",
      "Label 3: 35 times\n",
      "Label 0: 78 times\n",
      "Label 3: 54 times\n",
      "Label 0: 282 times\n",
      "Label 3: 101 times\n",
      "Label 0: 2187 times\n",
      "Label 3: 115 times\n",
      "Label 0: 109 times\n",
      "Label 3: 98 times\n",
      "Label 0: 39 times\n",
      "Label 3: 161 times\n",
      "Label 0: 148 times\n",
      "Label 3: 68 times\n",
      "Label 0: 150 times\n",
      "Label 3: 115 times\n",
      "Label 0: 1272 times\n",
      "Label 3: 142 times\n",
      "Label 0: 1564 times\n",
      "Label 3: 180 times\n",
      "Label 0: 1681 times\n",
      "Label 3: 107 times\n",
      "Label 0: 1234 times\n",
      "Label 3: 79 times\n",
      "Label 0: 6790 times\n",
      "Label 2: 4 times\n",
      "Label 3: 35 times\n",
      "Label 0: 201 times\n",
      "Label 2: 3 times\n",
      "Label 3: 85 times\n",
      "Label 0: 1593 times\n",
      "Label 3: 76 times\n",
      "Label 0: 14610 times\n",
      "Label 2: 5 times\n",
      "Label 3: 237 times\n",
      "Label 0: 38 times\n",
      "Label 3: 82 times\n",
      "Label 0: 17089 times\n",
      "Label 3: 17301 times\n",
      "Label 0: 6 times\n",
      "Label 3: 15155 times\n",
      "Label 0: 33 times\n",
      "Label 3: 2603 times\n",
      "Label 0: 104 times\n",
      "Label 3: 8774 times\n",
      "Label 0: 31 times\n",
      "Label 3: 680 times\n",
      "Label 0: 8 times\n",
      "Label 3: 49 times\n",
      "Label 0: 24 times\n",
      "Label 3: 892 times\n",
      "Label 0: 36 times\n",
      "Label 3: 418 times\n",
      "Label 0: 13 times\n",
      "Label 3: 5750 times\n",
      "Label 0: 659 times\n",
      "Label 3: 249 times\n",
      "Label 0: 34 times\n",
      "Label 3: 6422 times\n",
      "Label 0: 10 times\n",
      "Label 3: 16127 times\n",
      "Label 0: 9 times\n",
      "Label 3: 9485 times\n",
      "Label 0: 11 times\n",
      "Label 3: 272 times\n",
      "Label 0: 52 times\n",
      "Label 3: 2258 times\n",
      "Label 0: 24702 times\n",
      "Label 3: 75 times\n",
      "Label 0: 14331 times\n",
      "Label 3: 20889 times\n",
      "Label 0: 44399 times\n",
      "Label 2: 14 times\n",
      "Label 0: 6 times\n",
      "Label 3: 14025 times\n",
      "Label 0: 31 times\n",
      "Label 3: 1274 times\n",
      "Label 0: 57 times\n",
      "Label 3: 897 times\n",
      "Label 0: 134 times\n",
      "Label 3: 4327 times\n",
      "Label 0: 16 times\n",
      "Label 3: 45763 times\n",
      "Label 0: 302 times\n",
      "Label 3: 750 times\n",
      "Label 0: 201 times\n",
      "Label 3: 6827 times\n",
      "Label 0: 1014 times\n",
      "Label 3: 267 times\n",
      "Label 0: 158 times\n",
      "Label 3: 492 times\n",
      "Label 0: 561 times\n",
      "Label 3: 3403 times\n",
      "Label 0: 793 times\n",
      "Label 3: 55879 times\n",
      "Label 0: 34 times\n",
      "Label 3: 3492 times\n",
      "Label 0: 151 times\n",
      "Label 3: 126 times\n",
      "Label 0: 45 times\n",
      "Label 3: 94 times\n",
      "Label 0: 66599 times\n",
      "Label 3: 22466 times\n",
      "Label 0: 99 times\n",
      "Label 3: 237 times\n",
      "Label 0: 43796 times\n",
      "Label 3: 2132 times\n",
      "Label 0: 878 times\n",
      "Label 3: 17672 times\n",
      "Label 0: 138 times\n",
      "Label 3: 259 times\n",
      "Label 0: 839 times\n",
      "Label 3: 43 times\n",
      "Label 0: 275 times\n",
      "Label 3: 442 times\n",
      "Label 0: 56 times\n",
      "Label 3: 2220 times\n",
      "Label 0: 19 times\n",
      "Label 3: 1623 times\n",
      "Label 0: 221 times\n",
      "Label 3: 2040 times\n",
      "Label 0: 243 times\n",
      "Label 3: 225 times\n",
      "Label 0: 120 times\n",
      "Label 3: 78 times\n",
      "Label 0: 133 times\n",
      "Label 3: 59 times\n",
      "Label 0: 120 times\n",
      "Label 3: 228 times\n",
      "Label 0: 738 times\n",
      "Label 3: 113 times\n",
      "Label 0: 142 times\n",
      "Label 3: 239 times\n",
      "Label 0: 223 times\n",
      "Label 3: 61 times\n",
      "Label 0: 363 times\n",
      "Label 3: 82 times\n",
      "Label 0: 512 times\n",
      "Label 3: 269 times\n",
      "Label 0: 278 times\n",
      "Label 3: 74 times\n",
      "Label 0: 285 times\n",
      "Label 3: 31 times\n",
      "Label 0: 185 times\n",
      "Label 3: 77 times\n",
      "Label 0: 125 times\n",
      "Label 3: 1317 times\n",
      "Label 0: 260 times\n",
      "Label 3: 315 times\n",
      "Label 0: 50 times\n",
      "Label 3: 76 times\n",
      "Label 0: 189 times\n",
      "Label 3: 151 times\n",
      "Label 0: 197 times\n",
      "Label 3: 165 times\n",
      "Label 0: 241 times\n",
      "Label 3: 195 times\n",
      "Label 0: 80 times\n",
      "Label 3: 107 times\n",
      "Label 0: 398 times\n",
      "Label 3: 1170 times\n",
      "Label 0: 101 times\n",
      "Label 3: 948 times\n",
      "Label 0: 195 times\n",
      "Label 3: 188 times\n",
      "Label 0: 176 times\n",
      "Label 3: 136 times\n",
      "Label 0: 95 times\n",
      "Label 3: 136 times\n",
      "Label 0: 97 times\n",
      "Label 3: 136 times\n",
      "Label 0: 109 times\n",
      "Label 3: 61 times\n",
      "Label 0: 71 times\n",
      "Label 3: 565 times\n",
      "Label 0: 116 times\n",
      "Label 3: 66 times\n",
      "Label 0: 101 times\n",
      "Label 3: 85 times\n",
      "Label 0: 330 times\n",
      "Label 3: 146 times\n",
      "Label 0: 436 times\n",
      "Label 3: 234 times\n",
      "Label 0: 275 times\n",
      "Label 3: 280 times\n",
      "Label 0: 181 times\n",
      "Label 3: 112 times\n",
      "Label 0: 140 times\n",
      "Label 3: 192 times\n",
      "Label 0: 129 times\n",
      "Label 3: 130 times\n",
      "Label 0: 326 times\n",
      "Label 3: 283 times\n",
      "Label 0: 137 times\n",
      "Label 3: 221 times\n",
      "Label 0: 54 times\n",
      "Label 3: 217 times\n",
      "Label 0: 222 times\n",
      "Label 3: 180 times\n",
      "Label 0: 206 times\n",
      "Label 3: 290 times\n",
      "Label 0: 55 times\n",
      "Label 3: 204 times\n",
      "Label 0: 321 times\n",
      "Label 3: 1583 times\n",
      "Label 0: 101 times\n",
      "Label 3: 205 times\n",
      "Label 0: 260 times\n",
      "Label 3: 436 times\n",
      "Label 0: 152 times\n",
      "Label 3: 839 times\n",
      "Label 0: 207 times\n",
      "Label 3: 1007 times\n",
      "Label 0: 61 times\n",
      "Label 3: 193 times\n",
      "Label 0: 100 times\n",
      "Label 3: 850 times\n",
      "Label 0: 163 times\n",
      "Label 3: 383 times\n",
      "Label 0: 107 times\n",
      "Label 3: 246 times\n",
      "Label 0: 25 times\n",
      "Label 3: 2294 times\n",
      "Label 0: 133 times\n",
      "Label 3: 818 times\n",
      "Label 0: 415 times\n",
      "Label 3: 470 times\n",
      "Label 0: 202 times\n",
      "Label 3: 791 times\n",
      "Label 0: 107 times\n",
      "Label 3: 170 times\n",
      "Label 0: 48 times\n",
      "Label 3: 275 times\n",
      "Label 0: 21 times\n",
      "Label 3: 187 times\n",
      "Label 0: 141 times\n",
      "Label 3: 397 times\n",
      "Label 0: 135 times\n",
      "Label 3: 299 times\n",
      "Label 0: 78 times\n",
      "Label 1: 26 times\n",
      "Label 3: 517 times\n",
      "Label 0: 261 times\n",
      "Label 3: 452 times\n",
      "Label 0: 122 times\n",
      "Label 3: 1371 times\n",
      "Label 0: 123 times\n",
      "Label 3: 161 times\n",
      "Label 0: 12 times\n",
      "Label 3: 157 times\n",
      "Label 0: 163 times\n",
      "Label 3: 866 times\n",
      "Label 0: 162 times\n",
      "Label 3: 306 times\n",
      "Label 0: 46 times\n",
      "Label 3: 10319 times\n",
      "Label 0: 816 times\n",
      "Label 3: 3325 times\n",
      "Label 0: 1603 times\n",
      "Label 3: 11635 times\n",
      "Label 0: 1305 times\n",
      "Label 1: 20 times\n",
      "Label 0: 111 times\n",
      "Label 1: 36 times\n",
      "Label 0: 286 times\n",
      "Label 1: 444 times\n",
      "Label 0: 357 times\n",
      "Label 1: 7 times\n",
      "Label 0: 36 times\n",
      "Label 3: 41252 times\n",
      "Label 0: 194 times\n",
      "Label 3: 1081 times\n",
      "Label 0: 64 times\n",
      "Label 3: 11395 times\n",
      "Label 0: 44 times\n",
      "Label 3: 6759 times\n",
      "Label 0: 35 times\n",
      "Label 3: 5086 times\n",
      "Label 0: 308 times\n",
      "Label 3: 3844 times\n",
      "Label 0: 40 times\n",
      "Label 3: 28150 times\n",
      "Label 0: 36 times\n",
      "Label 3: 8420 times\n",
      "Label 0: 272 times\n",
      "Label 3: 4606 times\n",
      "Label 0: 35 times\n",
      "Label 3: 511 times\n",
      "Label 0: 113 times\n",
      "Label 3: 77 times\n",
      "Label 0: 290 times\n",
      "Label 3: 179 times\n",
      "Label 0: 122 times\n",
      "Label 3: 116 times\n",
      "Label 0: 5 times\n",
      "Label 3: 8 times\n",
      "Label 0: 887 times\n",
      "Label 3: 137 times\n",
      "Label 0: 154 times\n",
      "Label 3: 93 times\n",
      "Label 0: 145 times\n",
      "Label 3: 89 times\n",
      "Label 0: 105 times\n",
      "Label 3: 189 times\n",
      "Label 0: 1905 times\n",
      "Label 3: 205 times\n",
      "Label 0: 1575 times\n",
      "Label 3: 109 times\n",
      "Label 0: 9 times\n",
      "Label 3: 250 times\n",
      "Label 0: 882 times\n",
      "Label 3: 167 times\n",
      "Label 0: 274 times\n",
      "Label 3: 137 times\n",
      "Label 0: 155 times\n",
      "Label 3: 73 times\n",
      "Label 0: 1063 times\n",
      "Label 3: 185 times\n",
      "Label 0: 1281 times\n",
      "Label 3: 246 times\n",
      "Label 0: 28 times\n",
      "Label 3: 65 times\n",
      "Label 0: 4994 times\n",
      "Label 3: 280 times\n",
      "Label 0: 12700 times\n",
      "Label 3: 228 times\n",
      "Label 0: 86 times\n",
      "Label 3: 96 times\n",
      "Label 0: 777 times\n",
      "Label 3: 130 times\n",
      "Label 0: 1303 times\n",
      "Label 3: 158 times\n",
      "Label 0: 79 times\n",
      "Label 3: 67 times\n",
      "Label 0: 3237 times\n",
      "Label 3: 198 times\n",
      "Label 0: 1114 times\n",
      "Label 3: 298 times\n",
      "Label 0: 1830 times\n",
      "Label 3: 225 times\n",
      "Label 0: 21 times\n",
      "Label 3: 50 times\n",
      "Label 0: 17 times\n",
      "Label 3: 24 times\n",
      "Label 0: 10643 times\n",
      "Label 3: 324 times\n",
      "Label 0: 693 times\n",
      "Label 3: 302 times\n",
      "Label 0: 734 times\n",
      "Label 3: 219 times\n",
      "Label 0: 18 times\n",
      "Label 3: 59 times\n",
      "Label 0: 5198 times\n",
      "Label 3: 335 times\n",
      "Label 0: 111 times\n",
      "Label 3: 13063 times\n",
      "Label 0: 8 times\n",
      "Label 3: 2129 times\n",
      "Label 0: 11 times\n",
      "Label 3: 2949 times\n",
      "Label 0: 4 times\n",
      "Label 3: 2428 times\n",
      "Label 0: 8 times\n",
      "Label 3: 129 times\n",
      "Label 0: 21 times\n",
      "Label 3: 200 times\n",
      "Label 0: 9 times\n",
      "Label 3: 2059 times\n",
      "Label 0: 27 times\n",
      "Label 3: 11757 times\n",
      "Label 0: 85 times\n",
      "Label 3: 31711 times\n",
      "Label 0: 11053 times\n",
      "Label 1: 16 times\n",
      "Label 0: 35 times\n",
      "Label 1: 10 times\n",
      "Label 0: 80 times\n",
      "Label 3: 3655 times\n",
      "Label 0: 64 times\n",
      "Label 3: 15402 times\n",
      "Label 0: 31 times\n",
      "Label 3: 19849 times\n",
      "Label 0: 16404 times\n",
      "Label 3: 14196 times\n",
      "Label 0: 11438 times\n",
      "Label 1: 101 times\n",
      "Label 0: 40864 times\n",
      "Label 3: 20360 times\n",
      "Label 0: 35 times\n",
      "Label 3: 107 times\n",
      "Label 0: 6182 times\n"
     ]
    }
   ],
   "source": [
    "def count_consecutive_labels(labels):\n",
    "    if len(labels) == 0:\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    current_label = labels[0]\n",
    "    count = 1\n",
    "\n",
    "    for i in range(1, len(labels)):\n",
    "        if labels[i] == current_label:\n",
    "            count += 1\n",
    "        else:\n",
    "            result.append((current_label, count))\n",
    "            current_label = labels[i]\n",
    "            count = 1\n",
    "\n",
    "    # Append the last label count\n",
    "    result.append((current_label, count))\n",
    "    return result\n",
    "\n",
    "labels = tall_labels.reshape(-1)\n",
    "consecutive_counts = count_consecutive_labels(labels)\n",
    "\n",
    "for label, count in consecutive_counts:\n",
    "    print(f\"Label {label}: {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edb28381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProjector(nn.Module):\n",
    "    def __init__(self, input_size=156, output_size=32):\n",
    "        super(FeatureProjector, self).__init__()\n",
    "        \n",
    "        # 1D Convolutional Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=output_size, kernel_size=1)\n",
    "        \n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input x shape: (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # Permute to match Conv1D input: (batch_size, input_size, sequence_length)\n",
    "        x = x.float()\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # First convolutional layer\n",
    "        x = self.conv1(x)  # Shape: (batch_size, 128, sequence_length)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        x = self.conv2(x)  # Shape: (batch_size, 64, sequence_length)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        x = self.conv3(x)  # Shape: (batch_size, output_size, sequence_length)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Permute back to original order: (batch_size, sequence_length, output_size)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "953d02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProjector2(nn.Module):\n",
    "    def __init__(self, input_size=156, output_size=32):\n",
    "        super(FeatureProjector2, self).__init__()\n",
    "        \n",
    "        # 1D Convolutional Layers with ReLU activations and Batch Normalization\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=output_size, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(output_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input x shape: (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # Permute to match Conv1D input: (batch_size, input_size, sequence_length)\n",
    "        x = x.float()\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # First convolutional layer\n",
    "        x = self.conv1(x)  # Shape: (batch_size, 128, sequence_length - 2)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        x = self.conv2(x)  # Shape: (batch_size, 64, sequence_length - 4)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        x = self.conv3(x)  # Shape: (batch_size, output_size, sequence_length - 6)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # Permute back to original order: (batch_size, sequence_length - 6, output_size)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e18eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEncoder(nn.Module):\n",
    "    def __init__(self, input_size=102, output_size=64):\n",
    "        super(ECGEncoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_size, 32, kernel_size=7, stride=2, padding=3)  # Downsampling by 2\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=7, stride=2, padding=3)             # Downsampling by 2\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=7, stride=2, padding=3)            # Downsampling by 2\n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=7, stride=2, padding=3)           # Downsampling by 2\n",
    "        self.conv5 = nn.Conv1d(256, 512, kernel_size=7, stride=2, padding=3)           # Downsampling by 2\n",
    "        self.conv6 = nn.Conv1d(512, 1024, kernel_size=7, stride=2, padding=3)          # Downsampling by 2\n",
    "        \n",
    "        # Fully connected layer to map to the 64-dimensional output\n",
    "        self.fc = nn.Linear(1024, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Apply each convolutional layer with ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        # Global average pooling (to get a single vector for each channel)\n",
    "#         x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "        \n",
    "        # Final fully connected layer to produce 64-dimensional vector\n",
    "#         x = self.fc(x)\n",
    "#         x = x.permute(0, 2, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf0cec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def initialize_model_supervised(seed):\n",
    "    set_seed(seed)\n",
    "    model = FeatureProjector(input_size=252, output_size=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05a10daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "seed = 42\n",
    "attn_model = initialize_model_supervised(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e27134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:21<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 0.9088,          Train Accuracy: 75.25%, F1-score: 0.7724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 19.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Val Loss: 1.1100,          Val Accuracy: 59.67%, F1-score: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:21<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Train Loss: 0.6410,          Train Accuracy: 85.29%, F1-score: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Val Loss: 1.1634,          Val Accuracy: 58.28%, F1-score: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:21<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Train Loss: 0.5044,          Train Accuracy: 88.74%, F1-score: 0.8882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Val Loss: 1.2570,          Val Accuracy: 57.90%, F1-score: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:21<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Train Loss: 0.4209,          Train Accuracy: 90.08%, F1-score: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Val Loss: 1.0021,          Val Accuracy: 66.94%, F1-score: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:20<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Train Loss: 0.3419,          Train Accuracy: 92.30%, F1-score: 0.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 19.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Val Loss: 1.0164,          Val Accuracy: 62.81%, F1-score: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:20<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Train Loss: 0.2984,          Train Accuracy: 92.93%, F1-score: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Val Loss: 1.0772,          Val Accuracy: 59.25%, F1-score: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 321/321 [00:20<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Train Loss: 0.2669,          Train Accuracy: 93.40%, F1-score: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 80/80 [00:04<00:00, 19.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Val Loss: 1.0195,          Val Accuracy: 63.02%, F1-score: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|                                                                         | 164/321 [00:11<00:10, 15.01it/s]"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(attn_model.parameters(), lr=0.001)  # Example optimizer\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cpu\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\")\n",
    "attn_model.to(device)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    attn_model.train()  # Set the model to training mode\n",
    "    train_running_loss = 0.0\n",
    "    train_correct_predictions = 0\n",
    "    train_total_samples = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for time_series, labels in tqdm(train_loader):\n",
    "        time_series = time_series.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        features = attn_model(time_series)\n",
    "\n",
    "        # Flatten y_hat to have dimensions [batch_size * sequence_length, num_classes]\n",
    "        y_hat_flat = features.reshape(-1, features.size(-1))\n",
    "\n",
    "        # Reshape y to have dimensions [batch_size * sequence_length]\n",
    "        labels_flat = labels.view(-1)\n",
    "        \n",
    "        # Compute training loss\n",
    "        train_loss = criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training statistics\n",
    "        train_running_loss += train_loss.item() * time_series.size(0)\n",
    "        \n",
    "        _, predicted = torch.max(y_hat_flat, 1)\n",
    "        train_correct_predictions += (predicted == labels_flat).sum().item()\n",
    "        \n",
    "        #Store the labels for future computation of F1-score\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels_flat.cpu().numpy())\n",
    "        \n",
    "        train_total_samples += labels_flat.size(0)\n",
    "    \n",
    "    # Calculate average training loss and accuracy for the epoch\n",
    "    train_epoch_loss = train_running_loss / len(train_loader.dataset)\n",
    "    train_epoch_accuracy = 100*train_correct_predictions / train_total_samples\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds,average='weighted')\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_epoch_loss:.4f},\\\n",
    "          Train Accuracy: {train_epoch_accuracy:.2f}%, F1-score: {f1:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    attn_model.eval()  # Set the model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        for time_series, labels in tqdm(valid_loader):\n",
    "            time_series = time_series.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            features = attn_model(time_series)\n",
    "\n",
    "            # Flatten y_hat to have dimensions [batch_size * sequence_length, num_classes]\n",
    "            y_hat_flat = features.reshape(-1, features.size(-1))\n",
    "\n",
    "            # Reshape y to have dimensions [batch_size * sequence_length]\n",
    "            labels_flat = labels.view(-1)\n",
    "\n",
    "            # Compute validation loss\n",
    "            val_loss = criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "            # Update validation statistics\n",
    "            val_running_loss += val_loss.item() * time_series.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(y_hat_flat, 1)\n",
    "            val_correct_predictions += (predicted == labels_flat).sum().item()\n",
    "            val_total_samples += labels_flat.size(0)\n",
    "            \n",
    "            val_preds.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels_flat.cpu().numpy())\n",
    "    \n",
    "    # Calculate average validation loss and accuracy for the epoch\n",
    "    val_epoch_loss = val_running_loss / len(valid_loader.dataset)\n",
    "    val_epoch_accuracy = 100*val_correct_predictions / val_total_samples\n",
    "    \n",
    "    f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Val Loss: {val_epoch_loss:.4f},\\\n",
    "          Val Accuracy: {val_epoch_accuracy:.2f}%, F1-score: {f1:.2f}\")\n",
    "\n",
    "print(\"Training and validation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c729e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper dataset class to flatten the batches\n",
    "class FlattenedDataset(Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.num_batches = len(original_dataset)\n",
    "        self.batch_size = original_dataset[0][0].shape[0]  # Assuming shape [599, 156]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches * self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = idx // self.batch_size\n",
    "        sample_idx = idx % self.batch_size\n",
    "        data_batch, label_batch = self.original_dataset[batch_idx]\n",
    "        return data_batch[sample_idx], label_batch[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balanced_dataset(dataset, class_counts):\n",
    "    # Initialize dictionary to store indices of each class\n",
    "    class_indices = {label: [] for label in class_counts.keys()}\n",
    "    \n",
    "    # Populate class_indices with indices of each class\n",
    "    for idx in range(len(dataset)):\n",
    "        _, label = dataset[idx]\n",
    "        label = label.item()  # Ensure the label is a scalar\n",
    "        if label in class_indices:\n",
    "            class_indices[label].append(idx)\n",
    "\n",
    "    # Ensure each class has the required number of instances\n",
    "    balanced_indices = []\n",
    "    for label, count in class_counts.items():\n",
    "        if len(class_indices[label]) >= count:\n",
    "            balanced_indices.extend(random.sample(class_indices[label], count))\n",
    "        else:\n",
    "            raise ValueError(f\"Not enough instances of class {label} to satisfy the requested count\")\n",
    "\n",
    "    # Create a subset of the dataset with the balanced indices\n",
    "    balanced_subset = Subset(dataset, balanced_indices)\n",
    "    return balanced_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707648a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired count for each class\n",
    "desired_count_per_class = {0: 1577, 1: 972, 2: 459, 3: 1467}\n",
    "flattened_data = FlattenedDataset(valid_ds)\n",
    "\n",
    "# Load balanced dataset\n",
    "balanced_dataset = load_balanced_dataset(flattened_data, desired_count_per_class)\n",
    "\n",
    "# Create a DataLoader for the balanced dataset\n",
    "train_balanced_dataloader = DataLoader(balanced_dataset, batch_size=5000, shuffle=True, worker_init_fn=seed_worker)\n",
    "\n",
    "# # Print the labels in the balanced dataset to verify\n",
    "# for features_batch, labels_batch in train_balanced_dataloader:\n",
    "#     print(features_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to count occurrences of each class\n",
    "label_counts = {label: 0 for label in flipped_afib_dict}\n",
    "\n",
    "# Iterate through the dataloader to count label occurrences\n",
    "for _, labels in train_balanced_dataloader:\n",
    "    for label in labels:\n",
    "        label = label.item()  # Convert tensor to scalar\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "\n",
    "# Print the counts\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4acce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply PCA and visualize the results\n",
    "def visualize_pca2(images, labels, class_names, model):\n",
    "    # Flatten the images to vectors (assuming they are 2D images)\n",
    "#     flattened_images = images.view(images.size(0), -1).numpy()\n",
    "\n",
    "#     # Standardize the data before applying PCA\n",
    "#     scaler = StandardScaler()\n",
    "#     standardized_images = scaler.fit_transform(flattened_images)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    trained_pca = pca.fit(images.view(-1, images.size(-1)))\n",
    "    reduced_features = trained_pca.transform(images.view(-1, images.size(-1)))\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(4):\n",
    "        indices = labels == i\n",
    "        count = (labels == i).sum()\n",
    "        plt.scatter(reduced_features[indices, 0], reduced_features[indices, 1], label=class_names[i])\n",
    "\n",
    "    plt.title('PCA Visualization of Image Data')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        standardized_images = model(images)\n",
    "\n",
    "    trained_pca = pca.fit(standardized_images.view(-1, standardized_images.size(-1)))\n",
    "    reduced_features = trained_pca.transform(standardized_images.view(-1, standardized_images.size(-1)))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(4):\n",
    "        indices = labels == i\n",
    "        count = (labels == i).sum()\n",
    "        plt.scatter(reduced_features[indices, 0], reduced_features[indices, 1], label=class_names[i])\n",
    "\n",
    "    plt.title('PCA Visualization of Image Data (Resnet features)')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Get explained variance ratio\n",
    "    explained_variance_ratio = trained_pca.explained_variance_ratio_\n",
    "    cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    # Print explained variance ratio\n",
    "    print(\"Explained variance ratio:\", explained_variance_ratio)\n",
    "    print(\"Cumulative explained variance:\", cumulative_explained_variance)\n",
    "\n",
    "    # Plot explained variance ratio\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center', label='Individual explained variance')\n",
    "    plt.step(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, where='mid', label='Cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c6a70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming your dataset has a 'classes' attribute containing class names\n",
    "# class_names = dataset.clases\n",
    "\n",
    "# Assuming you have a DataLoader named 'train_loader'\n",
    "for batch in train_balanced_dataloader:\n",
    "    images, labeli = batch\n",
    "    images = images.view(-1, 1, images.shape[-1])\n",
    "    \n",
    "    visualize_pca2(images, labeli, flipped_afib_dict, attn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply t-SNE and visualize the results\n",
    "def visualize_tsne(images, labels, class_names, model):\n",
    "    # Flatten the images to vectors (assuming they are 2D images)\n",
    "    # Flatten the images to vectors (assuming they are 2D images)\n",
    "    flattened_images = images.view(images.size(0), -1).numpy()\n",
    "\n",
    "    # Standardize the data before applying t-SNE\n",
    "    scaler = StandardScaler()\n",
    "    standardized_images = scaler.fit_transform(flattened_images)\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_features = tsne.fit_transform(standardized_images)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(4):\n",
    "        indices = labels == i\n",
    "        plt.scatter(reduced_features[indices, 0], reduced_features[indices, 1], label=class_names[i])\n",
    "\n",
    "    plt.title('t-SNE Visualization of Image Data')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model and get features\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_features = model(images)\n",
    "\n",
    "    # Standardize model features before applying t-SNE\n",
    "    standardized_model_features = scaler.fit_transform(model_features.view(-1, model_features.size(-1)).cpu().numpy())\n",
    "\n",
    "    # Apply t-SNE to model features\n",
    "    reduced_features_model = tsne.fit_transform(standardized_model_features)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(4):\n",
    "        indices = labels == i\n",
    "        plt.scatter(reduced_features_model[indices, 0], reduced_features_model[indices, 1], label=class_names[i])\n",
    "\n",
    "    plt.title('t-SNE Visualization of Image Data (ResNet features)')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a71bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming your dataset has a 'classes' attribute containing class names\n",
    "# class_names = dataset.clases\n",
    "\n",
    "# Assuming you have a DataLoader named 'train_loader'\n",
    "for batch in train_balanced_dataloader:\n",
    "    images, labeli = batch\n",
    "    images = images.view(-1, 1, images.shape[-1])\n",
    "    \n",
    "    visualize_tsne(images, labeli, flipped_afib_dict, attn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16ec80",
   "metadata": {},
   "source": [
    "### 1. Dynamic Margin-CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68daee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HATCL_LOSS(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(HATCL_LOSS, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features):\n",
    "        # Normalize the feature vectors\n",
    "        features_normalized = F.normalize(features, dim=-1, p=2)\n",
    "\n",
    "        # Calculate the cosine similarity matrix\n",
    "        similarities = torch.matmul(features_normalized, features_normalized.T)\n",
    "        \n",
    "        exp_similarities = torch.exp(similarities / self.temperature)\n",
    "        \n",
    "        # Removing the similarity of a window with itself i.e main diagonal\n",
    "        exp_similarities = exp_similarities - torch.diag(exp_similarities.diag())        \n",
    "\n",
    "        # Lower diagonal elements represent positive pairs\n",
    "        positives = torch.diagonal(exp_similarities, offset=-1)\n",
    "\n",
    "        # The denominator is the sum of the column vectors minus the positives\n",
    "        denominator = torch.sum(exp_similarities[:,:-1], dim=0) - positives\n",
    "        \n",
    "        # Calculate NT-Xent loss\n",
    "        loss = -torch.log(positives / denominator).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7898d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LS_HATCL_LOSS(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(LS_HATCL_LOSS, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features):\n",
    "        \n",
    "        # Normalize the feature vectors\n",
    "        features_normalized = torch.nn.functional.normalize(features, p=2, dim=-1)\n",
    "\n",
    "        # Calculate the cosine similarity matrix\n",
    "        similarities = torch.matmul(features_normalized, features_normalized.T)\n",
    "\n",
    "        \n",
    "        exp_similarities = torch.exp(similarities / self.temperature)\n",
    "        \n",
    "        # Removing the similarity of a window with itself i.e main diagonal\n",
    "        exp_similarities = exp_similarities - torch.diag(exp_similarities.diag())        \n",
    "\n",
    "        # Lower diagonal elements represent positive pairs\n",
    "        lower_diag = torch.diagonal(exp_similarities, offset=-1)\n",
    "        \n",
    "        # The numerator is the sum of shifted left and right of the positive pairs\n",
    "        numerator = lower_diag[1:] + lower_diag[:-1]\n",
    "        \n",
    "        # The denominator is the sum of the column vectors minus the positives\n",
    "        denominator = torch.sum(exp_similarities[:,:-2], dim=0) - lower_diag[:-1]\\\n",
    "                + (torch.sum(exp_similarities[:,1:-1], dim=0)  - (lower_diag[1:] + lower_diag[:-1]))\n",
    "        \n",
    "        \n",
    "        # Calculate NT-Xent loss\n",
    "        loss = -torch.log(numerator / denominator).mean()\n",
    "        \n",
    "#         print(\"Similarities: \", similarities)\n",
    "#         print(\"Exp Similarities: \", exp_similarities)\n",
    "#         print(\"Numerator: \", numerator)\n",
    "#         print(\"Denominator: \", denominator)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(seed):\n",
    "    set_seed(seed)\n",
    "    model = FeatureProjector(input_size=252, output_size=32)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "seed = 42\n",
    "attn_model = initialize_model(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf97c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "cl_loss = LS_HATCL_LOSS(temperature=0.5)\n",
    "optimizer = optim.AdamW(attn_model.parameters(), lr=0.01)  # Example optimizer\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cpu\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\")\n",
    "attn_model.to(device)\n",
    "l = 0.4\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    attn_model.train()  # Set the model to training mode\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (time_series, labels) in enumerate(tqdm(train_loader)):\n",
    "        time_series = time_series.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        features = attn_model(time_series)\n",
    "        \n",
    "        linear_layer = nn.Linear(in_features=time_series.shape[-1], out_features=32)\n",
    "\n",
    "        scaled_timeseries = linear_layer(time_series.float())\n",
    "        mse_loss = F.mse_loss(scaled_timeseries, features)\n",
    "\n",
    "    \n",
    "        # Flatten features to have dimensions [batch_size * sequence_length, feature dim]\n",
    "        features = features.reshape(-1, features.size(-1))\n",
    "\n",
    "        # Compute training loss\n",
    "        contrast_loss = cl_loss(features)\n",
    "        \n",
    "#         print(mse_loss.item())\n",
    "#         print(contrast_loss.item())\n",
    "        \n",
    "        train_loss = l*mse_loss + (1-l)*contrast_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # Update training statistics\n",
    "        train_running_loss += train_loss.item() * time_series.size(0)\n",
    "\n",
    "#         # Log training loss to Wandb\n",
    "#         if config.WANDB and batch_idx % 10 == 0:\n",
    "#             wandb.log({'Train Loss': train_running_loss /(batch_idx + 1), 'Epoch': epoch})\n",
    "\n",
    "\n",
    "    train_epoch_loss = train_running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Davies-Bouldin Index\n",
    "db_index = davies_bouldin_score(images.squeeze(), labeli)\n",
    "ch_index = calinski_harabasz_score(images.squeeze(), labeli)\n",
    "slh_index = silhouette_score(images.squeeze(), labeli)\n",
    "\n",
    "print(f\"Davies-Bouldin Index: {db_index}\")\n",
    "print(f\"Calinski Harabasz Index: {ch_index}\")\n",
    "print(f\"Silhouette Index: {slh_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1496b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model.eval()\n",
    "with torch.no_grad():\n",
    "    features = attn_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=1).fit(features.detach().squeeze())\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "db_index2 = davies_bouldin_score(features.detach().squeeze(), cluster_labels)\n",
    "ch_index2 = calinski_harabasz_score(features.detach().squeeze(), cluster_labels)\n",
    "slh_index2 = silhouette_score(features.detach().squeeze(), cluster_labels)\n",
    "\n",
    "print(f\"Davies-Bouldin Index Features: {db_index2}\")\n",
    "print(f\"Calinski Harabasz Index Features: {ch_index2}\")\n",
    "print(f\"Silhouette Index Features: {slh_index2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tsne(images, labeli, flipped_afib_dict, attn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa0cf8",
   "metadata": {},
   "source": [
    "## Linear Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f728d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Define a frozen backbone and a linear classifier\n",
    "class LinearEvaluation(nn.Module):\n",
    "    def __init__(self, backbone, num_classes):\n",
    "        super(LinearEvaluation, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone.requires_grad_(False)\n",
    "        self.classifier = nn.Linear(32, num_classes)  # Add linear classifier\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():  # Ensure backbone is not updated\n",
    "            features = self.backbone(x)  # Extract features using frozen backbone\n",
    "            \n",
    "        return self.classifier(features)  # Feed features to linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_backbone_frozen(model):\n",
    "    frozen = True\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            frozen = False\n",
    "            break\n",
    "    return frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d77f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_evaluation(train_loader, valid_loader, algorithms, seeds, num_epochs):\n",
    "    diction_algs = {}\n",
    "        \n",
    "    \n",
    "    for alg in algorithms:\n",
    "        seed_acc = []\n",
    "        seed_f1 = []\n",
    "        seed_prec = []\n",
    "        seed_recall = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            set_seed(seed)\n",
    "            frozen_backbone = FeatureProjector(input_size=252, output_size=32)\n",
    "            frozen_backbone.load_state_dict(torch.load(f'models/my_models/ecg{seed}_{alg}_model_epoch_500.pth',\n",
    "                                            map_location=torch.device('cpu')))\n",
    "            \n",
    "            \n",
    "            num_activities = 4\n",
    "            mine_model = LinearEvaluation(frozen_backbone, num_classes=num_activities)\n",
    "            # Define loss function and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(mine_model.parameters(), lr=0.001)  # Example optimizer\n",
    "\n",
    "            # Move model to device\n",
    "            device = torch.device(\"cpu\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\")\n",
    "            mine_model.to(device)\n",
    "\n",
    "            # Training and validation loop\n",
    "            num_epochs = num_epochs\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                # Training phase\n",
    "                mine_model.train()  # Set the model to training mode\n",
    "                train_running_loss = 0.0\n",
    "                train_correct_predictions = 0\n",
    "                train_total_samples = 0\n",
    "\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "\n",
    "                for time_series, labels in (train_loader):\n",
    "                    time_series = time_series.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    features = mine_model(time_series)\n",
    "                    # Flatten y_hat to have dimensions [batch_size * sequence_length, num_classes]\n",
    "                    y_hat_flat = features.reshape(-1, features.size(-1))\n",
    "\n",
    "                    # Reshape y to have dimensions [batch_size * sequence_length]\n",
    "                    labels_flat = labels.view(-1)\n",
    "\n",
    "                    # Compute training loss\n",
    "                    train_loss = criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    train_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Update training statistics\n",
    "                    train_running_loss += train_loss.item() * time_series.size(0)\n",
    "\n",
    "                    _, predicted = torch.max(y_hat_flat, 1)\n",
    "                    train_correct_predictions += (predicted == labels_flat).sum().item()\n",
    "\n",
    "                    #Store the labels for future computation of F1-score\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels_flat.cpu().numpy())\n",
    "\n",
    "                    train_total_samples += labels_flat.size(0)\n",
    "\n",
    "                # Calculate average training loss and accuracy for the epoch\n",
    "                train_epoch_loss = train_running_loss / len(train_loader.dataset)\n",
    "                train_epoch_accuracy = 100*train_correct_predictions / train_total_samples\n",
    "\n",
    "                f1 = f1_score(all_labels, all_preds,average='weighted')\n",
    "\n",
    "#                 print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_epoch_loss:.4f},\\\n",
    "#                       Train Accuracy: {train_epoch_accuracy:.2f}%, F1-score: {f1:.4f}\")\n",
    "                \n",
    "            # Validation phase\n",
    "            mine_model.eval()  # Set the model to evaluation mode\n",
    "            val_running_loss = 0.0\n",
    "            val_correct_predictions = 0\n",
    "            val_total_samples = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                for time_series, labels in (valid_loader):\n",
    "                    time_series = time_series.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    features = mine_model(time_series)\n",
    "\n",
    "                    # Flatten y_hat to have dimensions [batch_size * sequence_length, num_classes]\n",
    "                    y_hat_flat = features.reshape(-1, features.size(-1))\n",
    "\n",
    "                    # Reshape y to have dimensions [batch_size * sequence_length]\n",
    "                    labels_flat = labels.view(-1)\n",
    "\n",
    "                    # Compute validation loss\n",
    "                    val_loss = criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "                    # Update validation statistics\n",
    "                    val_running_loss += val_loss.item() * time_series.size(0)\n",
    "\n",
    "                    _, predicted = torch.max(y_hat_flat, 1)\n",
    "                    val_correct_predictions += (predicted == labels_flat).sum().item()\n",
    "                    val_total_samples += labels_flat.size(0)\n",
    "\n",
    "                    val_preds.extend(predicted.cpu().numpy())\n",
    "                    val_labels.extend(labels_flat.cpu().numpy())\n",
    "\n",
    "            # Calculate average validation loss and accuracy for the epoch\n",
    "            val_epoch_loss = val_running_loss / len(valid_loader.dataset)\n",
    "            val_epoch_accuracy = 100*val_correct_predictions / val_total_samples\n",
    "\n",
    "            # Precision and recall using sklearn\n",
    "            precision = precision_score(val_labels, val_preds, average='macro')\n",
    "            recall = recall_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "            f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "#             print(f\"Epoch {epoch + 1}/{num_epochs}, Val Loss: {val_epoch_loss:.4f},\\\n",
    "#                   Val Accuracy: {val_epoch_accuracy:.2f}%, F1-score: {f1:.2f},\\\n",
    "#                   Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "            \n",
    "            \n",
    "            seed_acc.append((round(val_epoch_accuracy,2)))\n",
    "            seed_f1.append((round(f1,2)))\n",
    "            seed_prec.append((round(precision,2)))\n",
    "            seed_recall.append((round(recall,2)))\n",
    "            \n",
    "            \n",
    "        diction_algs[f'{alg}'] = [(round(np.mean(seed_acc),2), round(np.std(seed_acc),2)),\n",
    "                                   (round(np.mean(seed_f1),2), round(np.std(seed_f1),2)),\n",
    "                                   (round(np.mean(seed_prec),2), round(np.std(seed_prec),2)),\n",
    "                                   (round(np.mean(seed_recall),2), round(np.std(seed_recall),2))]\n",
    "        \n",
    "    return diction_algs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = ['vanilla', 'marginCL', 'tnc', 'cpc', 'ts2vec', 'infoTS']\n",
    "# seeds = [42, 53, 64, 75]\n",
    "# num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8918aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['cost']\n",
    "seeds = [42, 53, 64, 75]\n",
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc348da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_data = linear_evaluation(train_loader, valid_loader, algorithms, seeds, num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05019361",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply t-SNE and visualize the results\n",
    "def visualize_tsne123(images, colors, labels, class_names, model):\n",
    "\n",
    "    # Evaluate the model and get features\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_features = model(images)\n",
    "\n",
    "    # Standardize the data before applying t-SNE\n",
    "    scaler = StandardScaler()\n",
    "    tsne = TSNE(n_components=2, init='random', learning_rate='auto')\n",
    "\n",
    "    # Standardize model features before applying t-SNE\n",
    "    standardized_model_features = scaler.fit_transform(model_features.view(-1, model_features.size(-1)).cpu().numpy())\n",
    "\n",
    "    # Apply t-SNE to model features\n",
    "    reduced_features_model = tsne.fit_transform(standardized_model_features)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i, val in enumerate([0, 1, 2]):\n",
    "        indices = labels == val\n",
    "        plt.scatter(reduced_features_model[indices, 0], reduced_features_model[indices, 1], color =colors[i], label=class_names[val])\n",
    "\n",
    "#     plt.title('t-SNE Visualization of Image Data (ResNet features)')\n",
    "#     plt.xlabel('t-SNE Component 1')\n",
    "#     plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.legend(prop={'size': 14, 'family': 'Tahoma'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureProjector(input_size=252, output_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'models/my_models/ecg53_cost_model_epoch_500.pth',\n",
    "                                            map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['vanilla', 'tnc', 'cpc', 'ts2vec', 'infoTS', 'triplet', 'doubleCL', 'marginCL', 'recons', 'monoselfPAB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_afib_dict = {0: \"AFIB\", 1: \"AFL\", 2: \"J\", 3: \"N\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbae86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset has a 'classes' attribute containing class names\n",
    "# class_names = dataset.clases\n",
    "\n",
    "# Assuming you have a DataLoader named 'train_loader'\n",
    "for batch in train_balanced_dataloader:\n",
    "    images, labeli = batch\n",
    "    images = images.view(-1, 1, images.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your class names and corresponding colors for 5 classes\n",
    "class_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3']\n",
    "colors = ['#1F64A1', '#A9A9A9', '#8B4513', '#2E8B57']  # Blue, Light Gray, Brown, Green\n",
    "\n",
    "# Assume `images`, `labels`, and `model` are already defined\n",
    "# `labeli` corresponds to the labels for the images, `class_dict` is a dictionary mapping labels to class names\n",
    "visualize_tsne123(images, colors, labeli, flipped_afib_dict, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
